{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dbe5598-c617-4211-9f05-74ab7b524c9b",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "302250f1-04e1-4ac6-be39-85bde408a43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 20:18:10.975838: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-06 20:18:10.987870: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-06 20:18:11.000966: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8473] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-06 20:18:11.004939: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1471] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-06 20:18:11.015761: I tensorflow/core/platform/cpu_feature_guard.cc:211] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor, AutoModelForImageTextToText\n",
    "import torch\n",
    "from qwen_vl_utils import process_vision_info\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1d25a6-3c9e-49f7-8dad-7ae4c3376e28",
   "metadata": {},
   "source": [
    "### Loading model and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d695b2c-4382-494e-a303-dcca4242543e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8932f213d56d455fba4845d260d6e188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "# Load model and tokenizer\n",
    "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id, \n",
    "    device_map=\"auto\", \n",
    "    torch_dtype=torch.bfloat16\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55287660-a331-4f6d-a922-8c568e926979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using adapter\n",
    "adapter_path = \"adapter_path\"\n",
    "model.load_adapter(adapter_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96874e0c-0739-4504-85e0-eb4a0c64ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\n",
    "    \"NER_annotations_with_texts_2_TestTrainVal_Qwen7BftOCR.json\", \"r\", encoding=\"utf-8\"\n",
    ") as fr:\n",
    "    data = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb5a34ae-7faa-4905-91c7-6a633e925782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ORG', 'DATE', 'PERSON', 'LOCATION'}\n"
     ]
    }
   ],
   "source": [
    "unique_ner = list()\n",
    "for i in range(len(data[\"annotations\"])):\n",
    "    annotation = data[\"annotations\"][i]\n",
    "    attributes = annotation.get(\"attributes\", {})\n",
    "\n",
    "    if \"TestTrainVal\" not in attributes:\n",
    "        continue\n",
    "    labels = [ent[\"entity\"] for ent in attributes.get(\"ner_entities\", [])]\n",
    "    unique_ner.extend(labels)\n",
    "print(set(unique_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a346137-d734-4fcb-a70d-9c7dd472b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing Dataset: 100%|██████████| 89788/89788 [00:00<00:00, 111709.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize dataset structure\n",
    "dataset = {\"input_text\": [], \"label\": [], \"split\": []}\n",
    "for annotation in tqdm(data[\"annotations\"], desc=\"Preparing Dataset\"):\n",
    "    attributes = annotation.get(\"attributes\", {})\n",
    "    if \"TestTrainVal\" not in attributes:\n",
    "        continue\n",
    "    labels = [\n",
    "        {\"entity\": ent[\"entity\"], \"text\": ent[\"text\"]}\n",
    "        for ent in attributes.get(\"ner_entities\", [])\n",
    "    ]\n",
    "\n",
    "    dataset_key = attributes[\"TestTrainVal\"]\n",
    "    dataset[\"label\"].append(labels)\n",
    "    dataset[\"input_text\"].append(attributes[\"Text\"]) # this is the ground truth text - can be changed to OCR text\n",
    "    dataset[\"split\"].append(\n",
    "        attributes[\"TestTrainVal\"]\n",
    "    )  # Stores \"train\", \"test\", or \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f544306b-c3d1-40af-bdda-846dd3f1bed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert dictionary to Hugging Face dataset\n",
    "hf_dataset = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa573f95-fd96-479a-9e15-f1e28320f19e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b968a54443d24b5cb89e2fdbfef2903e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0799108287a94ce6b625f1373ea5c5fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0756fa1c734c7b894642c361c3b03d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/11030 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split dataset based on the \"split\" column\n",
    "train_dataset = hf_dataset.filter(lambda x: x[\"split\"] == \"train\")\n",
    "test_dataset = hf_dataset.filter(lambda x: x[\"split\"] == \"test\")\n",
    "val_dataset = hf_dataset.filter(lambda x: x[\"split\"] == \"val\")\n",
    "\n",
    "# Remove the \"split\" column as it's no longer needed\n",
    "train_dataset = train_dataset.remove_columns(\"split\")\n",
    "test_dataset = test_dataset.remove_columns(\"split\")\n",
    "val_dataset = val_dataset.remove_columns(\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b995964-e900-4470-8c7e-1c0d54744957",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a Language Model specialized in detecting named entities in Ukrainian texts.\n",
    "Your task is to analyze the provided text and identify named entities such as names, locations, organizations, and other key terms.\n",
    "Respond concisely, typically providing the detected entities as a structured list or short phrases.\n",
    "Focus on accuracy and ensure the extracted entities reflect the text. Avoid additional explanations unless absolutely necessary.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Analyze the provided Ukrainian text. \n",
    "Detect and extract named entities belonging to the following categories:\n",
    "- PERSON (names of individuals)\n",
    "- LOCATION (geographical places, cities, countries)\n",
    "- DATE (specific dates, years, or time-related expressions)\n",
    "- ORG (organizations, institutions, or companies)\n",
    "\n",
    "Respond with a structured list of detected entities along with their corresponding entity types. \n",
    "Ensure accuracy and avoid adding unnecessary explanations.\"\"\"\n",
    "\n",
    "text_prompt = \"\"\"Text:\\n\"\"\"\n",
    "\n",
    "\n",
    "def format_data(sample):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_prompt + sample[\"input_text\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": json.dumps(sample[\"label\"], indent=2, ensure_ascii=False),\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7a1f519-6e93-4746-b790-e1f14ceeb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [format_data(sample) for sample in train_dataset]\n",
    "val_dataset = [format_data(sample) for sample in val_dataset]\n",
    "test_dataset = [format_data(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1a75546-1a47-4d92-8293-7d1676218f75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'You are a Language Model specialized in detecting named entities in Ukrainian texts.\\nYour task is to analyze the provided text and identify named entities such as names, locations, organizations, and other key terms.\\nRespond concisely, typically providing the detected entities as a structured list or short phrases.\\nFocus on accuracy and ensure the extracted entities reflect the text. Avoid additional explanations unless absolutely necessary.'}]},\n",
       " {'role': 'user',\n",
       "  'content': [{'type': 'text',\n",
       "    'text': 'Analyze the provided Ukrainian text. \\nDetect and extract named entities belonging to the following categories:\\n- PERSON (names of individuals)\\n- LOCATION (geographical places, cities, countries)\\n- DATE (specific dates, years, or time-related expressions)\\n- ORG (organizations, institutions, or companies)\\n\\nRespond with a structured list of detected entities along with their corresponding entity types. \\nEnsure accuracy and avoid adding unnecessary explanations.'},\n",
       "   {'type': 'text', 'text': 'Text:\\n4. Место рождения'}]}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this will be sent to model\n",
    "train_dataset[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "191ba5a0-22da-4837-ade8-1251996d2a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate function - prepares all necessary data for the inference\n",
    "def generate_text_from_sample(model, processor, sample, max_new_tokens=1024, device=\"cuda\"):\n",
    "    # Prepare the text input by applying the chat template\n",
    "    text_input = processor.apply_chat_template(\n",
    "        sample[1:2], tokenize=False, add_generation_prompt=True  # Use the sample without the system message\n",
    "    )\n",
    "\n",
    "    # Process the visual input from the sample\n",
    "    #image_inputs, _ = process_vision_info(sample)\n",
    "\n",
    "    # Prepare the inputs for the model\n",
    "    model_inputs = processor(\n",
    "        text=[text_input],\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\n",
    "        device\n",
    "    )  # Move inputs to the specified device\n",
    "\n",
    "    # Generate text with the model\n",
    "    generated_ids = model.generate(**model_inputs, max_new_tokens=max_new_tokens, temperature=0.1)\n",
    "\n",
    "    # Trim the generated ids to remove the input ids\n",
    "    trimmed_generated_ids = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(model_inputs.input_ids, generated_ids)]\n",
    "\n",
    "    # Decode the output text\n",
    "    output_text = processor.batch_decode(\n",
    "        trimmed_generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "    )\n",
    "\n",
    "    return output_text[0]  # Return the first decoded output text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ee01900-5b04-4186-9da3-62fded36d8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text: Text:\n",
      "5. Мылом по\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "4. Сахаром по\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "3. Выдано талонов на питание\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "2. Сухим пайком на путь следования на\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "1. Продовольствием в натуре по\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Номер и дата документа\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Без подписей и гербовой печати, а также без предъявления документа, подтверждающего нахождение военнослужащего вне пределов части, аттестат недействителен. За подделку аттестата виновные подвергаются ответственности по суду.\n",
      "Model Prediction:  [{'entity': 'DATE', 'text': '1945 года'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Руководствуясь ст. ст. 93 п. 2 и 108 УПК УССР.\n",
      "Model Prediction:  [{'entity': 'LOCATION', 'text': 'УССР'}]\n",
      "Truth Data:  [{'entity': 'LOCATION', 'text': 'УССР'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Отдела УМГБ Закарпатской области\n",
      "Model Prediction:  [{'entity': 'ORG', 'text': 'УМГБ'}, {'entity': 'LOCATION', 'text': 'Закарпатской'}]\n",
      "Truth Data:  [{'entity': 'ORG', 'text': 'УМГБ'}, {'entity': 'LOCATION', 'text': 'Закарпатской'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "и найдя, что\n",
      "Model Prediction:  [{'entity': 'LOCATION', 'text': 'Украиной'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Копией настоящего постановления уведомить прокурора и Отдел \"А\" УМГБ З. О.\n",
      "Model Prediction:  [{'entity': 'ORG', 'text': 'УМГБ'}, {'entity': 'PERSON', 'text': 'З.'}]\n",
      "Truth Data:  [{'entity': 'ORG', 'text': 'УМГБ'}, {'entity': 'LOCATION', 'text': 'З.'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "С какого времени и где содержится под стражей\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Фамилия докладчика и должность\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "года рождения, осужденного Особым Совещанием\n",
      "Model Prediction:  [{'entity': 'DATE', 'text': '1940'}, {'entity': 'ORG', 'text': 'Особым Совещанием'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Рассмотрев поступившие материалы о преступной деятельности: Фамилия МИЦОВДА Имя и отчество Мария Михайловна Год рождения І930 место рожд. село Заусино, Велико-Березненского округа З. О. Профессия и специальность не имеет Место работы и должность крестьянка в своем хозяйстве парт. Образование 8 классов нац. украинка гр-во СССР Семейное положение не замужняя.\n",
      "Model Prediction:  [{'entity': 'PERSON', 'text': 'МИЦОВДА'}, {'entity': 'PERSON', 'text': 'Мария Михайловна'}, {'entity': 'DATE', 'text': 'I930'}, {'entity': 'LOCATION', 'text': 'Заусино'}, {'entity': 'ORG', 'text': 'Велико-Березненского'}, {'entity': 'ORG', 'text': 'З. О.'}]\n",
      "Truth Data:  [{'entity': 'PERSON', 'text': 'МИЦОВДА'}, {'entity': 'PERSON', 'text': 'Мария Михайловна'}, {'entity': 'LOCATION', 'text': 'Заусино'}, {'entity': 'LOCATION', 'text': 'Велико-Березненского'}, {'entity': 'LOCATION', 'text': 'З.'}, {'entity': 'LOCATION', 'text': 'СССР'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "6. Нац. и гражд. (подданство)\n",
      "Model Prediction:  [{'entity': 'LOCATION', 'text': 'Україна'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "8. Род занятий\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "9. Социальное происхождение\n",
      "Model Prediction:  [{'entity': 'DATE', 'text': '1938'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "(род занятий родителей и их имущественное положение)\n",
      "Model Prediction:  [{'entity': 'PERSON', 'text': 'родителей'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "10. Социальное положение (род занятий и имущественное положение)\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "а) до революции\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "б) после революции\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "11. Состав семьи\n",
      "Model Prediction:  [{'entity': 'PERSON', 'text': 'семьи'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "допросил в качестве\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "3. Дата рождения\n",
      "Model Prediction:  [{'entity': 'DATE', 'text': 'Дата рождения'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "К ДЕЛУ №\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "(место службы и должность)\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Отдела УМГБ Закарпатской области\n",
      "Model Prediction:  [{'entity': 'ORG', 'text': 'УМГБ'}, {'entity': 'LOCATION', 'text': 'Закарпатской'}]\n",
      "Truth Data:  [{'entity': 'ORG', 'text': 'УМГБ'}, {'entity': 'LOCATION', 'text': 'Закарпатской'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Руководствуясь ст. ст. 93 п. 2 и 108 УПК УССР.\n",
      "Model Prediction:  [{'entity': 'LOCATION', 'text': 'УССР'}]\n",
      "Truth Data:  [{'entity': 'LOCATION', 'text': 'УССР'}]\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "17. Служба в Красной армии(красной гвардии, в партизанских отрядах) когда и в качестве кого\n",
      "Model Prediction:  [{'entity': 'ORG', 'text': 'Красной армии'}, {'entity': 'ORG', 'text': 'красной гвардии'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "18. Служба в белых и др. к-р. армиях (когда, в качестве кого)\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "16. Категория воинского учета запаса и где состоит на учете\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "13. Партийность (в прошлом и настоящем)\n",
      "Model Prediction:  [{'entity': 'LOCATION', 'text': 'Украиной'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "б) после революции\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "а) до революции\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "12. Образование (общее, специальное)\n",
      "Model Prediction:  [{'entity': 'DATE', 'text': '12'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "20. Сведения об общественно-политической деятельности\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Характер використання (копіювання, виписки, перегляд і т. д.)\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "11. Рот: малый, большой. Углы рта: опущены, приподняты.\n",
      "Model Prediction:  [{'entity': 'LOCATION', 'text': 'Рот: малый, большой.'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Прочие особенности и привычки\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "указать наименование документа, орган и дату\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Сдано в архив\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "название учетного аппарата\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "в настоящем постановлении.\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "в качестве обвиняемого по ст. ст.\n",
      "Model Prediction:  [{'entity': 'LOCATION', 'text': 'Украинской ССР'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "Настоящее постановление мне объявлено\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "8. Род занятий\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "К ДЕЛУ №\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "допросил в качестве\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "3. Дата рождения\n",
      "Model Prediction:  [{'entity': 'DATE', 'text': 'Дата рождения'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "(место службы и должность)\n",
      "Model Prediction:  []\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Input text: Text:\n",
      "(род занятий родителей и их имущественное положение)\n",
      "Model Prediction:  [{'entity': 'PERSON', 'text': 'родителей'}]\n",
      "Truth Data:  []\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(test_dataset)-1):\n",
    "    output = generate_text_from_sample(model, processor, test_dataset[i])\n",
    "    print('Input text:', test_dataset[i][1]['content'][1]['text'])\n",
    "    print('Model Prediction: ', eval(output))\n",
    "    print('Truth Data: ', eval(test_dataset[i][2]['content'][0]['text']))\n",
    "    #display(test_dataset[i][1]['content'][0]['image'])\n",
    "    print('-'*100)\n",
    "    if i > 50:\n",
    "        break\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
