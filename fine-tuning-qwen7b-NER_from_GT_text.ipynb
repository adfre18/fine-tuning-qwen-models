{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1436971c-e467-4eb7-899f-05507f83400a",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "!pip install  -U -q git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git datasets bitsandbytes peft qwen-vl-utils wandb accelerate\n",
    "# Tested with transformers==4.47.0.dev0, trl==0.12.0.dev0, datasets==3.0.2, bitsandbytes==0.44.1, peft==0.13.2, qwen-vl-utils==0.0.8, wandb==0.18.5, accelerate==1.0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9226e593-ffc0-43de-9267-4e7dea5bc476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\n",
    "    \"NER_annotations_with_texts_2_TestTrainVal_Qwen7BftOCR.json\", \"r\", encoding=\"utf-8\"\n",
    ") as fr:\n",
    "    data = json.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05025f6c-d238-405a-98dc-f0d12d85c949",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "unique_ner = list()\n",
    "for i in range(len(data[\"annotations\"])):\n",
    "    annotation = data[\"annotations\"][i]\n",
    "    attributes = annotation.get(\"attributes\", {})\n",
    "\n",
    "    if \"TestTrainVal\" not in attributes:\n",
    "        continue\n",
    "    labels = [ent[\"entity\"] for ent in attributes.get(\"ner_entities\", [])]\n",
    "    unique_ner.extend(labels)\n",
    "print(set(unique_ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302d2405-deea-4cc6-bbbb-095c9f3d7006",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize dataset structure\n",
    "dataset = {\"input_text\": [], \"label\": [], \"split\": []}\n",
    "for annotation in tqdm(data[\"annotations\"], desc=\"Preparing Dataset\"):\n",
    "    attributes = annotation.get(\"attributes\", {})\n",
    "    if \"TestTrainVal\" not in attributes:\n",
    "        continue\n",
    "    labels = [\n",
    "        {\"entity\": ent[\"entity\"], \"text\": ent[\"text\"]}\n",
    "        for ent in attributes.get(\"ner_entities\", [])\n",
    "    ]\n",
    "\n",
    "    dataset_key = attributes[\"TestTrainVal\"]\n",
    "    dataset[\"label\"].append(labels)\n",
    "    dataset[\"input_text\"].append(attributes[\"Text\"])\n",
    "    dataset[\"split\"].append(\n",
    "        attributes[\"TestTrainVal\"]\n",
    "    )  # Stores \"train\", \"test\", or \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f79189-66f6-40b8-928c-48fa48bc017c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# Convert dictionary to Hugging Face dataset\n",
    "hf_dataset = Dataset.from_dict(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91ba9655-5581-46c6-abf1-3f799126316d",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "# Split dataset based on the \"split\" column\n",
    "train_dataset = hf_dataset.filter(lambda x: x[\"split\"] == \"train\")\n",
    "test_dataset = hf_dataset.filter(lambda x: x[\"split\"] == \"test\")\n",
    "val_dataset = hf_dataset.filter(lambda x: x[\"split\"] == \"val\")\n",
    "\n",
    "# Remove the \"split\" column as it's no longer needed\n",
    "train_dataset = train_dataset.remove_columns(\"split\")\n",
    "test_dataset = test_dataset.remove_columns(\"split\")\n",
    "val_dataset = val_dataset.remove_columns(\"split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2056a35a-5f44-4d7a-808b-75bafcbe9e00",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "len(hf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0253d570-7fe8-4e88-a209-7f322c355db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"\"\"You are a Language Model specialized in detecting named entities in Ukrainian texts.\n",
    "Your task is to analyze the provided text and identify named entities such as names, locations, organizations, and other key terms.\n",
    "Respond concisely, typically providing the detected entities as a structured list or short phrases.\n",
    "Focus on accuracy and ensure the extracted entities reflect the text. Avoid additional explanations unless absolutely necessary.\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"Analyze the provided Ukrainian text. \n",
    "Detect and extract named entities belonging to the following categories:\n",
    "- PERSON (names of individuals)\n",
    "- LOCATION (geographical places, cities, countries)\n",
    "- DATE (specific dates, years, or time-related expressions)\n",
    "- ORG (organizations, institutions, or companies)\n",
    "\n",
    "Respond with a structured list of detected entities along with their corresponding entity types. \n",
    "Ensure accuracy and avoid adding unnecessary explanations.\"\"\"\n",
    "\n",
    "text_prompt = \"\"\"Text:\\n\"\"\"\n",
    "\n",
    "\n",
    "def format_data(sample):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": system_message}],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": user_prompt,\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text_prompt + sample[\"input_text\"],\n",
    "                },\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": [\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": json.dumps(sample[\"label\"], indent=2, ensure_ascii=False),\n",
    "                }\n",
    "            ],\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40f1e9da-b60c-4236-87c1-5fd2d1b11f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = [format_data(sample) for sample in train_dataset]\n",
    "val_dataset = [format_data(sample) for sample in val_dataset]\n",
    "test_dataset = [format_data(sample) for sample in test_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edb64952-9e5c-44db-9d7b-1cc9aad5ba18",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def clear_memory():\n",
    "    # Delete variables if they exist in the current global scope\n",
    "    if \"inputs\" in globals():\n",
    "        del globals()[\"inputs\"]\n",
    "    if \"model\" in globals():\n",
    "        del globals()[\"model\"]\n",
    "    if \"processor\" in globals():\n",
    "        del globals()[\"processor\"]\n",
    "    if \"trainer\" in globals():\n",
    "        del globals()[\"trainer\"]\n",
    "    if \"peft_model\" in globals():\n",
    "        del globals()[\"peft_model\"]\n",
    "    if \"bnb_config\" in globals():\n",
    "        del globals()[\"bnb_config\"]\n",
    "    time.sleep(2)\n",
    "\n",
    "    # Garbage collection and clearing CUDA memory\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    time.sleep(2)\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    model = None\n",
    "    processor = None\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    gc.collect()\n",
    "    time.sleep(2)\n",
    "    print(f\"GPU allocated memory: {torch.cuda.memory_allocated() / 1024**3:.2f} GB\")\n",
    "    print(f\"GPU reserved memory: {torch.cuda.memory_reserved() / 1024**3:.2f} GB\")\n",
    "\n",
    "\n",
    "clear_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a450a1b-9592-40f7-9f09-5ac4050fb305",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, BitsAndBytesConfig, AutoModelForImageTextToText\n",
    "\n",
    "# , AutoModelForImageTextToText\n",
    "model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n",
    "\n",
    "# BitsAndBytesConfig int-4 config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForImageTextToText.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b247da4-5e28-4001-8212-2fe73e9eb29f",
   "metadata": {},
   "outputs": [
 
   ],
   "source": [
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "# Configure LoRA\n",
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    r=8,\n",
    "    bias=\"none\",\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Apply PEFT model adaptation\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "\n",
    "# Print trainable parameters\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd48cd71-8b22-4a98-8e75-2d8c28c8b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "387cf5b1-566c-4324-bf65-039e38fef858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "# Configure training arguments\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"qwen2.5-7b-instruct-trl-sft-NAKI-NER-from-GT-text\",  # Directory to save the model\n",
    "    num_train_epochs=8,  # Number of training epochs\n",
    "    per_device_train_batch_size=4,  # Batch size for training\n",
    "    per_device_eval_batch_size=4,  # Batch size for evaluation\n",
    "    gradient_accumulation_steps=8,  # Steps to accumulate gradients\n",
    "    gradient_checkpointing=True,  # Enable gradient checkpointing for memory efficiency\n",
    "    # Optimizer and scheduler settings\n",
    "    optim=\"adamw_torch_fused\",  # Optimizer type\n",
    "    learning_rate=2e-4,  # Learning rate for training\n",
    "    lr_scheduler_type=\"linear\",  # Type of learning rate scheduler\n",
    "    # Logging and evaluation\n",
    "    logging_steps=10,  # Steps interval for logging\n",
    "    eval_steps=100,  # Steps interval for evaluation\n",
    "    eval_strategy=\"steps\",  # Strategy for evaluation\n",
    "    save_strategy=\"steps\",  # Strategy for saving the model\n",
    "    save_steps=100,  # Steps interval for saving\n",
    "    metric_for_best_model=\"eval_loss\",  # Metric to evaluate the best model\n",
    "    greater_is_better=False,  # Whether higher metric values are better\n",
    "    load_best_model_at_end=True,  # Load the best model after training\n",
    "    # Mixed precision and gradient settings\n",
    "    bf16=True,  # Use bfloat16 precision\n",
    "    tf32=True,  # Use TensorFloat-32 precision\n",
    "    max_grad_norm=0.3,  # Maximum norm for gradient clipping\n",
    "    warmup_ratio=0.03,  # Ratio of total steps for warmup\n",
    "    # Hub and reporting\n",
    "    push_to_hub=False,  # Whether to push model to Hugging Face Hub\n",
    "    report_to=\"none\",  # Reporting tool for tracking metrics\n",
    "    # Gradient checkpointing settings\n",
    "    gradient_checkpointing_kwargs={\n",
    "        \"use_reentrant\": False\n",
    "    },  # Options for gradient checkpointing\n",
    "    # Dataset configuration\n",
    "    dataset_text_field=\"\",  # Text field in dataset\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True},  # Additional dataset options\n",
    "    # max_seq_length=1024  # Maximum sequence length for input\n",
    ")\n",
    "\n",
    "training_args.remove_unused_columns = False  # Keep unused columns in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f80eece-11a7-484f-8dd8-b996584c886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qwen_vl_utils import process_vision_info\n",
    "from transformers import Qwen2_5_VLProcessor\n",
    "\n",
    "\n",
    "# Create a data collator to encode text and image pairs\n",
    "def collate_fn(examples):\n",
    "    # Get the texts and images, and apply the chat template\n",
    "    texts = [\n",
    "        processor.apply_chat_template(example, tokenize=False) for example in examples\n",
    "    ]  # Prepare texts for processing\n",
    "    #image_inputs = [\n",
    "    #    process_vision_info(example)[0] for example in examples\n",
    "    #]  # Process the images to extract inputs\n",
    "\n",
    "    # Tokenize the texts and process the images\n",
    "    batch = processor(\n",
    "        text=texts, return_tensors=\"pt\", padding=True\n",
    "    )  # Encode texts and images into tensors\n",
    "\n",
    "    # The labels are the input_ids, and we mask the padding tokens in the loss computation\n",
    "    labels = batch[\"input_ids\"].clone()  # Clone input IDs for labels\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = (\n",
    "        -100\n",
    "    )  # Mask padding tokens in labels\n",
    "\n",
    "    # Ignore the image token index in the loss computation (model specific)\n",
    "    if isinstance(\n",
    "        processor, Qwen2_5_VLProcessor\n",
    "    ):  # Check if the processor is Qwen2VLProcessor\n",
    "        image_tokens = [\n",
    "            151652,\n",
    "            151653,\n",
    "            151655,\n",
    "        ]  # Specific image token IDs for Qwen2VLProcessor\n",
    "    else:\n",
    "        image_tokens = [\n",
    "            processor.tokenizer.convert_tokens_to_ids(processor.image_token)\n",
    "        ]  # Convert image token to ID\n",
    "\n",
    "    # Mask image token IDs in the labels\n",
    "    for image_token_id in image_tokens:\n",
    "        labels[labels == image_token_id] = -100  # Mask image token IDs in labels\n",
    "\n",
    "    batch[\"labels\"] = labels  # Add labels to the batch\n",
    "\n",
    "    return batch  # Return the prepared batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbd2f084-6991-4e1b-81e5-cfad965669b8",
   "metadata": {},
   "outputs": [
    
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    peft_config=peft_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc18e60-cee0-46b0-a2a7-fccf9a357dcf",
   "metadata": {},
   "outputs": [

   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6a80c0-6598-4c3b-ba94-e3de36baa2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce5e202-e034-4dcc-8321-a6c576a1260c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
